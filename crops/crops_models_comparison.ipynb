{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the models\n",
    "In this notebook we will be comparing the four models that we individually trained and judge which one is the best.  \n",
    "We will start by displaying relevant metrics for each models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Emalisa's model: PyCaret XGBoost\n",
    "\n",
    "|      | MAE    | MSE    | RMSE   | R2     | RMSLE  | MAPE   |\n",
    "|------|--------|--------|--------|--------|--------|--------|\n",
    "| Mean | 0.0320 | 0.0021 | 0.0462 | 0.9894 | 0.0226 | 0.0226 |\n",
    "| Std  | 0.0014 | 0.0002 | 0.0026 | 0.0014 | 0.0020 | 0.0020 |\n",
    "\n",
    "**Residuals**  \n",
    "<br/>\n",
    "<img src=\"../img/ea_residuals.png\" width=\"500\"/>  \n",
    "<br/>\n",
    "**Prediction Error**  \n",
    "<br/>\n",
    "<img src=\"../img/ea_predictionerror.png\" width=\"500\"/>  \n",
    "<br/>\n",
    "**Feature Importance**  \n",
    "<br/>\n",
    "<img src=\"../img/ea_featureimportance.png\" width=\"500\"/>  \n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Liesa's Model: AWS XGBoost\n",
    "\n",
    "**info**\n",
    "<br/>\n",
    "<img src=\"../img/mse_crops_Liesa.png\" width=\"250\"/>  \n",
    "\n",
    "\n",
    "**Arima**\n",
    "<br/>\n",
    "<img src=\"../img/info_predictions_crops_Liesa.png\" width=\"500\"/>\n",
    "<br/>\n",
    "<img src=\"../img/autocorrelation_crops_Liesa.png\" width=\"500\"/>\n",
    "<br/>\n",
    "<img src=\"../img/partial_autocorrelation_crops_Liesa.png\" width=\"500\"/>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hannah's Model: AWS Linear Regression\n",
    "\n",
    "**Info**\n",
    "<br/>\n",
    "<img src=\"../img/info_linear_regression_hannah.png\" width=\"250\"/>  \n",
    "\n",
    "**Residual analysis**\n",
    "<br/>\n",
    "<img src=\"../img/residual_analysis_linear_regression_hannah.png\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jeffrey's Model: Pycaret KNeighborsRegressor\n",
    "|      | MAE    | MSE    | RMSE   | R2     | RMSLE  | MAPE   |\n",
    "|------|--------|--------|--------|--------|--------|--------|\n",
    "| Mean | 0.0606 | 0.0228 | 0.1501 | 0.9914 | 0.0290 | 0.0264 |\n",
    "| Std  | 0.0041 | 0.0049 | 0.0162 | 0.0016 | 0.0034 | 0.0020 |\n",
    "\n",
    "**Residuals**  \n",
    "<br/>\n",
    "<img src=\"../img/js_residuals.png\" width=\"500\"/>  \n",
    "<br/>\n",
    "**Prediction Error**  \n",
    "<br/>\n",
    "<img src=\"../img/js_predictionerror.png\" width=\"500\"/>  \n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jeffrey's Model: Manual RandomForestRegressor\n",
    "\n",
    "| MAE    | MSE    | RMSE   | R2     | \n",
    "|--------|--------|--------|--------|\n",
    "| 0.1357 | 0.0458 | 0.2141 | 0.9831 |\n",
    "\n",
    "\n",
    "**Residuals**  \n",
    "<br/>\n",
    "<img src=\"../img/js_residualsm.png\" width=\"500\"/>  \n",
    "<br/>\n",
    "**Prediction Error**  \n",
    "<br/>\n",
    "<img src=\"../img/js_predictionerrorm.png\" width=\"500\"/>  \n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison\n",
    "These models were more difficult to compare as our mathematical knowledge is too limited to have valuable insights in all the values we retrieved with training our models, but we will give it our best shot based on the knowledge we gained during this course.  \n",
    "Let's start off with the linear regression model we trained with AWS. We chose this one as it seemed to perform decent during the PyCaret analysis but not the best, maybe we could improve it using Amazon Sagemaker. On first sight, looking at the low MSE, this model seems to perform decent. However, we see a systematic error occur when looking at the residuals: the difference between the predicted yield and the actual yield increases as the yield to be predicted increases. This error could be due to the model being trained on too little features: only the logarithmic values for yield, production and hectares were used to train this model. We suspect that including year in the dataframe could have helped to prevent this error. We saw, in the models that were trained with PyCaret, that this was an important feature. In the EDA we also saw that the yield drastically increased with the years, so it would make sense that omitting year would lead to larger errors for larger yields.  \n",
    "The other model we trained with AWS was an XGBoost model. This one seems to perform poorly, based on the high MSE. This could be due to the fact that this model was trained on the non-logarithmically transformed values for yield, production, and hectares. Using the logarithmic values for these features improved the performance of some of the other models we trained.   \n",
    "The results of the final three models are similar, for differences this small it is difficult to judge without extensive mathematical background. We decided that it is more harmful to predict yields that are too high than yields that are too low (we are envisioning a scenario wherein someone will be using our model to predict how much profit they can expect). Going off of this the next best model would be the manually trained RandomForestRegressor. Looking at the residuals and prediction errors this model seems to perform well, but we do see that this model has mostly positive residual values, which means it is likely to predict yields that are too high, which we determined to be harmful.  \n",
    "The next best model would be the PyCaret trained KNeighborsRegressor model. This one seems to primarily predict yields that are too low which is good. However, the error residuals are higher than in the last model.  \n",
    "Our last model is the PyCaret trained XGBoost model. This one seems the lowest residual errors. It also seems to have the least variation in prediction errors. This is why we deem this one to be the best performing ones.  \n",
    "In conclusion, when assuming a situation wherein predicting yields that are too high is more harmful than predicting ones that are too low, we find our PyCaret trained XGBoost model to be the best performing.  \n",
    "From this project we learned that it seems to be much easier to use PyCaret due to the precalculated visuals, the best model selection and tuning. This is good to use for beginners and to first look at the best models to create. AWS could be better in use by professionals in the workfield. This is better to use when storing large datasets and/or data in the cloud. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
