{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xlrd\n",
    "import warnings, requests, zipfile, io\n",
    "warnings.simplefilter('ignore')\n",
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sagemaker.image_uris import retrieve\n",
    "import sagemaker\n",
    "import requests\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import boto3\n",
    "import io\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the GitHub URL of the ZIP file\n",
    "github_url = 'https://github.com/mjochen/CloudAI/raw/master/Exercises/files/food-twentieth-century-crop-statistics-1900-2017-xlsx.zip'\n",
    "\n",
    "# Step 1: Download the ZIP file from GitHub\n",
    "response = requests.get(github_url)\n",
    "\n",
    "# ... (previous code)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # Step 2: Read the ZIP file content into a BytesIO object\n",
    "    zip_data = io.BytesIO(response.content)\n",
    "\n",
    "    # Step 3: Extract the Excel file from the ZIP\n",
    "    with zipfile.ZipFile(zip_data, 'r') as zip_ref:\n",
    "        # Assuming there's only one file in the ZIP, you can extract it\n",
    "        file_list = zip_ref.namelist()\n",
    "        if len(file_list) > 0:\n",
    "            with zip_ref.open(file_list[0]) as extracted_file:\n",
    "                # List all sheet names in the Excel file\n",
    "                sheet_names = pd.ExcelFile(extracted_file).sheet_names\n",
    "                # Check if 'CropStats' is in the list of sheet names\n",
    "                if 'CropStats' in sheet_names:\n",
    "                    df = pd.read_excel(extracted_file, sheet_name='CropStats', engine='openpyxl', usecols=lambda name: name != 'Unnamed: 0')\n",
    "                    # Now, you can work with the DataFrame 'df' as usual\n",
    "                else:\n",
    "                    print(\"The 'CropStats' sheet does not exist in the Excel file.\")\n",
    "        else:\n",
    "            print(\"The ZIP file is empty.\")\n",
    "else:\n",
    "    print(\"Failed to retrieve the ZIP file from GitHub.\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['admin2', 'notes', 'Harvest_year'], axis=1, inplace=True)\n",
    "df.rename(columns = {'admin0': 'national', 'admin1': 'subnational', 'hectares (ha)': 'hectares_ha', 'production (tonnes)': 'production_tonnes', 'yield(tonnes/ha)': 'yield_tonnes_ha'}, inplace=True)\n",
    "df.loc[df['subnational'].isna(), 'subnational'] = df['national']\n",
    "df.shape\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test_and_validate = train_test_split(df, \n",
    "                                            test_size=0.2, \n",
    "                                            random_state=42)\n",
    "#                                             stratify=df_wine['quality'])\n",
    "test, validate = train_test_split(test_and_validate, \n",
    "                                  test_size=0.5, \n",
    "                                  random_state=42)\n",
    "#                                   stratify=test_and_validate['quality'])\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(validate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket='c93435a2086654l4910637t1w0854223549-sandboxbucket-jtqmwpnickrd'\n",
    "prefix='CropDataModelHannah'\n",
    "train_file='wine_train.csv'\n",
    "test_file='wine_test.csv'\n",
    "validate_file='wine_validate.csv'\n",
    "whole_file='wine.csv'\n",
    "s3_resource = boto3.Session().resource('s3')\n",
    "\n",
    "def upload_s3_csv(filename, folder, dataframe):\n",
    "    csv_buffer = io.StringIO()\n",
    "    dataframe.to_csv(csv_buffer, header=False, index=False )\n",
    "    s3_resource.Bucket(bucket).Object(os.path.join(prefix, folder, filename)).put(Body=csv_buffer.getvalue())\n",
    "\n",
    "upload_s3_csv(train_file, 'train', train)\n",
    "upload_s3_csv(test_file, 'test', test)\n",
    "upload_s3_csv(validate_file, 'validate', validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.image_uris import retrieve\n",
    "import sagemaker\n",
    "role=sagemaker.get_execution_role()\n",
    "s3_output_location=\"s3://{}/{}/output/\".format(bucket,prefix)\n",
    "container = retrieve('xgboost',boto3.Session().region_name,'1.0-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams={\n",
    "    \"num_round\":\"20\",\n",
    "    \"num_class\":\"7\",\n",
    "    \"objective\":\"multi:softmax\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model=sagemaker.estimator.Estimator(container,\n",
    "                                        role,\n",
    "                                        instance_count=1,\n",
    "                                        instance_type='ml.m4.xlarge',\n",
    "                                        output_path=s3_output_location,\n",
    "                                        hyperparameters=hyperparams,\n",
    "                                        sagemaker_session=sagemaker.Session())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_channel = sagemaker.inputs.TrainingInput(\n",
    "    \"s3://{}/{}/train/\".format(bucket,prefix,train_file),\n",
    "    content_type='text/csv')\n",
    "\n",
    "validate_channel = sagemaker.inputs.TrainingInput(\n",
    "    \"s3://{}/{}/validate/\".format(bucket,prefix,validate_file),\n",
    "    content_type='text/csv')\n",
    "\n",
    "data_channels = {'train': train_channel, 'validation': validate_channel}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model.fit(inputs=data_channels, logs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=sagemaker.analytics.TrainingJobAnalytics(xgb_model._current_job_name, \n",
    "                                         metric_names = ['train:merror', \n",
    "                                                         'validation:merror']\n",
    "                                        )\n",
    "\n",
    "s_df=s.dataframe()\n",
    "s_df = s_df.iloc[:,1:3]\n",
    "s_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
