{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings, requests, zipfile, io \n",
    "warnings.simplefilter('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "from scipy.io import arff\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sagemaker.image_uris import retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to the ZIP file and the extraction directory\n",
    "zip_file_path = 'food-twentieth-century-crop-statistics-1900-2017-xlsx.zip'  # Replace with the actual path to your ZIP file\n",
    "extraction_path = './data'  # Specify the directory where you want to extract the contents\n",
    "\n",
    "# Extract the ZIP file\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extraction_path)\n",
    "\n",
    "# List the files in the extraction directory to see the extracted files\n",
    "extracted_files = os.listdir(extraction_path)\n",
    "print(\"Extracted files:\", extracted_files)\n",
    "\n",
    "# Assuming you want to read the first Excel file in the extraction directory\n",
    "excel_file_path = os.path.join(extraction_path, extracted_files[0])\n",
    "df = pd.read_excel(excel_file_path)\n",
    "\n",
    "# Now, 'df' contains your data as a DataFrame that you can work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Excel file\n",
    "file = pd.ExcelFile(\"data/food-twentieth-century-crop-statistics-1900-2017-xlsx.xlsx\")\n",
    "\n",
    "# Read data from a specific sheet (e.g., 'CropStats')\n",
    "sheet_name = 'CropStats'  # Replace with the name of the sheet you want to load\n",
    "df = file.parse(sheet_name)\n",
    "\n",
    "# Set the index to the first column and remove the index name\n",
    "df = df.set_index(df.columns[0])\n",
    "df.index.name = None\n",
    "\n",
    "# Now, 'df' contains the data from the specified sheet with the index set as described.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning\n",
    "#df.drop(['admin2', 'notes', 'Harvest_year'], axis=1, inplace=True)\n",
    "df.rename(columns = {'admin0': 'national', 'admin1': 'subnational', 'hectares (ha)': 'hectares_ha', 'production (tonnes)': 'production_tonnes', 'yield(tonnes/ha)': 'yield_tonnes_ha'}, inplace=True)\n",
    "df.loc[df['subnational'].isna(), 'subnational'] = df['national']\n",
    "\n",
    "mask = df['yield_tonnes_ha'].isna() & ~df['production_tonnes'].isna() & ~df['hectares_ha'].isna() & df['hectares_ha'] != 0\n",
    "df.loc[mask, 'yield_tonnes_ha'] = df['production_tonnes'] / df['hectares_ha']\n",
    "df.dropna(subset=['yield_tonnes_ha'], inplace=True)\n",
    "len(df[~pd.isnull(df['hectares_ha']) & pd.isnull(df['production_tonnes']) & ~pd.isnull(df['yield_tonnes_ha'])])\n",
    "# The mask is used here because of I did the same way as above it kept timing out\n",
    "mask = df['production_tonnes'].isna() & ~df['yield_tonnes_ha'].isna() & ~df['hectares_ha'].isna()\n",
    "df.loc[mask, 'production_tonnes'] = df['yield_tonnes_ha'] * df['hectares_ha']\n",
    "df.dropna(subset=['production_tonnes'], inplace=True)\n",
    "mask = df['hectares_ha'].isna() & ~df['yield_tonnes_ha'].isna() & ~df['production_tonnes'].isna()\n",
    "df.loc[mask, 'hectares_ha'] = df['yield_tonnes_ha'] * df['production_tonnes']\n",
    "df.dropna(subset=['hectares_ha'], inplace=True)\n",
    "# The columns we just adapted just changed into objects, let's make them floats again\n",
    "df['hectares_ha'] = df['hectares_ha'].astype(float)\n",
    "df['production_tonnes'] = df['production_tonnes'].astype(float)\n",
    "df['yield_tonnes_ha'] = df['yield_tonnes_ha'].astype(float)\n",
    "df['log_yield'] = np.log1p(df['yield_tonnes_ha'])\n",
    "df['log_hectares'] = np.log1p(df['hectares_ha'])\n",
    "df['log_production'] = np.log1p(df['production_tonnes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data sample\n",
    "df.shape\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and validate model\n",
    "train, test_and_validate = train_test_split(df, \n",
    "                                            test_size=0.2, \n",
    "                                            random_state=42) \n",
    "                                            #stratify=df['yield_tonnes_ha'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test and validate model\n",
    "test, validate = train_test_split(test_and_validate, \n",
    "                                  test_size=0.5, \n",
    "                                  random_state=42)\n",
    "                                 #stratify=df['yield(tonnes/ha)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(validate.shape)\n",
    "\n",
    "t1 = train['yield_tonnes_ha'].value_counts()\n",
    "t2 = test['yield_tonnes_ha'].value_counts()\n",
    "t3 = validate['yield_tonnes_ha'].value_counts()\n",
    "result = pd.concat([t1,t2,t3], axis=1, sort=False)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload to s3 bucket\n",
    "bucket='c93435a2086654l5105130t1w6478590828-sandboxbucket-qute15kbvwmy'\n",
    "prefix='mod03-demo-training-a-model'\n",
    "train_file='crop_train.csv'\n",
    "test_file='crop_test.csv'\n",
    "validate_file='crop_validate.csv'\n",
    "whole_file='crop.csv'\n",
    "s3_resource = boto3.Session().resource('s3')\n",
    "\n",
    "def upload_s3_csv(filename, folder, dataframe):\n",
    "    csv_buffer = io.StringIO()\n",
    "    dataframe.to_csv(csv_buffer, header=False, index=False )\n",
    "    s3_resource.Bucket(bucket).Object(os.path.join(prefix, folder, filename)).put(Body=csv_buffer.getvalue())\n",
    "\n",
    "upload_s3_csv(train_file, 'train', train)\n",
    "upload_s3_csv(test_file, 'test', test)\n",
    "upload_s3_csv(validate_file, 'validate', validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role=sagemaker.get_execution_role()\n",
    "s3_output_location=\"s3://{}/{}/output/\".format(bucket,prefix)\n",
    "container = retrieve('xgboost',boto3.Session().region_name,'1.0-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams={\n",
    "    \"num_round\":\"40\",\n",
    "    \"num_class\":\"7\",\n",
    "    \"objective\":\"multi:softmax\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model=sagemaker.estimator.Estimator(container,\n",
    "                                        role,\n",
    "                                        instance_count=1,\n",
    "                                        instance_type='ml.m4.xlarge',\n",
    "                                        output_path=s3_output_location,\n",
    "                                        hyperparameters=hyperparams,\n",
    "                                        sagemaker_session=sagemaker.Session())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_channel = sagemaker.inputs.TrainingInput(\n",
    "    \"s3://{}/{}/train/\".format(bucket,prefix,train_file),\n",
    "    content_type='text/csv')\n",
    "\n",
    "validate_channel = sagemaker.inputs.TrainingInput(\n",
    "    \"s3://{}/{}/validate/\".format(bucket,prefix,validate_file),\n",
    "    content_type='text/csv')\n",
    "\n",
    "data_channels = {'train': train_channel, 'validation': validate_channel}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input channels\n",
    "xgb_model.fit(inputs=data_channels, logs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=sagemaker.analytics.TrainingJobAnalytics(xgb_model._current_job_name, \n",
    "                                         metric_names = ['train:merror', \n",
    "                                                         'validation:merror']\n",
    "                                        )\n",
    "\n",
    "s_df=s.dataframe()\n",
    "s_df = s_df.iloc[:,1:3]\n",
    "s_df\n",
    "#(wrong cases)/#(all cases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='yellow'>This model gives back double 0</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=sagemaker.analytics.TrainingJobAnalytics(xgb_model._current_job_name, \n",
    "                                         metric_names = ['train:merror', \n",
    "                                                         'validation:merror']\n",
    "                                        )\n",
    "\n",
    "s_df=s.dataframe()\n",
    "s_df = s_df.iloc[:,1:12]\n",
    "s_df\n",
    "#(wrong cases)/#(all cases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='yellow'>This model gives back double 0</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams={\n",
    "    \"num_round\":\"40\",\n",
    "    \"num_class\":\"11\",\n",
    "    \"objective\":\"multi:softmax\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model=sagemaker.estimator.Estimator(container,\n",
    "                                        role,\n",
    "                                        instance_count=11,\n",
    "                                        instance_type='ml.m4.xlarge',\n",
    "                                        output_path=s3_output_location,\n",
    "                                        hyperparameters=hyperparams,\n",
    "                                        sagemaker_session=sagemaker.Session())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='yellow'>This model gives back 6 times 0</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
